{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up workspace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from statsmodels.tools import add_constant\n",
    "\n",
    "os.chdir('/Users/thomashill/Documents/Education/Fall 2017/Comp Sci/Final Project/Data/dataset/Cities_dfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in files\n",
    "def read_city(city):\n",
    "    businesses = pd.read_csv(str(city)+'_businesses.csv')\n",
    "    users = pd.read_csv(str(city)+'_users.csv')\n",
    "    reviews_orig = pd.read_csv(str(city)+'_reviews.csv')\n",
    "    \n",
    "    reviews_df = reviews_orig.pivot(index = 'user_id', columns ='business_id', values = 'stars') # used to have : .fillna(0)\n",
    "    \n",
    "    return {'businesses': businesses, 'users': users, 'reviews_df': reviews_df, 'original reviews': reviews_orig}\n",
    "\n",
    "\n",
    "Montreal_dfs = read_city('Montréal')\n",
    "\n",
    "businesses = Montreal_dfs['businesses']\n",
    "\n",
    "users = Montreal_dfs['users']\n",
    "users['yelping_since'] = [datetime.strptime(i, '%Y-%m-%d') for i in users['yelping_since']]\n",
    "users['indexed_id'] = range(1, len(users) + 1)\n",
    "\n",
    "orig_reviews = Montreal_dfs['original reviews']\n",
    "\n",
    "reviews_df = Montreal_dfs['reviews_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cleaning and merging\n",
    "\n",
    "#drop unnecessary columns\n",
    "businesses = businesses.drop('Unnamed: 0', 1)\n",
    "users = users.drop('Unnamed: 0', 1)\n",
    "orig_reviews = orig_reviews.drop('Unnamed: 0', 1)\n",
    "\n",
    "#Rename columns to prevent duplicates in merged dataframe\n",
    "businesses = businesses.rename(columns={'stars': 'business_stars','name':'business_name','review_count':'business_review_count'})\n",
    "orig_reviews = orig_reviews.rename(columns={'cool':'review_cool','date':'review_date','funny':'review_funny','useful':'review_useful'})\n",
    "users = users.rename(columns={'cool':'user_cool_count','fan':'user_fans','friends':'user_friends','funny':'user_funny_count','name':'user_name','review_count':'user_review_count','useful':'user_useful_count'})\n",
    "\n",
    "#Merging datasets\n",
    "df_1 = pd.merge(orig_reviews, users, on='user_id')\n",
    "df_total = pd.merge(df_1, businesses, on='business_id')\n",
    "df_total = df_total.drop('business_stars',1) #Drop columns of values that must be calculated endogenously within train and test sets\n",
    "df_total = df_total.drop('average_stars',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Formulas to return baseline scores of individual businesses and users\n",
    "\n",
    "def business_baseline(train_df,business_id,business_total_avg_stars):\n",
    "    average_stars = np.average(train_df['stars'], weights=(train_df['business_id']==business_id))\n",
    "    divergence = average_stars - business_total_avg_stars\n",
    "\n",
    "    return divergence\n",
    "\n",
    "def user_baseline(train_df,user_id,user_total_avg_stars):\n",
    "    average_stars = np.average(train_df['stars'], weights=(train_df['user_id']==user_id))\n",
    "    divergence = average_stars - user_total_avg_stars   \n",
    "\n",
    "    return divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_score(dataframe,business_id,user_id):\n",
    "    return dataframe[business_id][user_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's split our data into train and test, and use RMSE to evaluate the performance of this approach to calculating baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df_total,stratify=df_total['user_id'],random_state=1990)\n",
    "train = train[train['business_id'].isin(test['business_id'])] #This makes sure there is overlap in train and test for both\n",
    "test = test[test['business_id'].isin(train['business_id'])]\n",
    "train = train[train['user_id'].isin(test['user_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FORMULA TO RETURN VECTORS OF PREDICTED and ACTUAL VALUES\n",
    "def baseline_predictions(train,test):\n",
    "    user_ids = list(set(train['user_id']))\n",
    "    business_ids = list(set(train['business_id']))\n",
    "    \n",
    "    #Getting user and business averages for full matrix    \n",
    "    business_list = list(set(train['business_id']))\n",
    "    user_list = list(set(train['user_id']))\n",
    "    \n",
    "    business_average_stars = []\n",
    "    for i in business_list:\n",
    "        average_stars = np.average(train['stars'], weights=(train['business_id']==i))\n",
    "        business_average_stars.append(average_stars)\n",
    "    business_total_avg_stars = np.mean(business_average_stars) #These averages are literally averages of averages - which I think we want\n",
    "    \n",
    "    user_average_stars = [] \n",
    "    for i in user_list:\n",
    "        average_stars = np.average(train['stars'], weights=(train['user_id']==i))\n",
    "        user_average_stars.append(average_stars)\n",
    "    user_total_avg_stars = np.mean(user_average_stars)\n",
    "    \n",
    "    \n",
    "    \n",
    "    user_baselines = []\n",
    "    for i in user_ids:\n",
    "        a = user_baseline(train,i,user_total_avg_stars)\n",
    "        user_baselines.append(a)\n",
    "    \n",
    "    business_baselines = []\n",
    "    for i in business_ids:\n",
    "        a = business_baseline(train,i,business_total_avg_stars)\n",
    "        business_baselines.append(a)\n",
    "\n",
    "    #Create matrices of user and business average scores, and then add them\n",
    "    business_baselines_matrix = np.tile(business_baselines,(len(user_baselines),1))\n",
    "    user_baselines_matrix = np.tile(user_baselines,(len(business_baselines),1)).transpose()\n",
    "    \n",
    "    overall_avg_stars = np.mean(train['stars']) #Perhaps change how this average is calculated\n",
    "    \n",
    "    master_baselines_matrix = np.add(business_baselines_matrix,user_baselines_matrix) #Sum the two matrices\n",
    "    master_baselines_matrix = master_baselines_matrix + overall_avg_stars #Add the average stars from the train dataframe\n",
    "\n",
    "    #Turn numpy matrix into pandas dataframe with labels for columns and rows\n",
    "    master_baselines_dataframe = pd.DataFrame(data=master_baselines_matrix,index=user_ids,columns=business_ids)\n",
    "    \n",
    "    #Test component: \n",
    "    \n",
    "    #In order to test the accuracy of this, create a dataframe of user-business interactions that actually happened\n",
    "    test_user_business_combos = list(zip(test['business_id'],\n",
    "                                         test['user_id'],\n",
    "                                         test['stars']))\n",
    "    \n",
    "    train_user_business_combos = list(zip(train['business_id'],\n",
    "                                         train['user_id'],\n",
    "                                         train['stars']))\n",
    "\n",
    "    train_predicted_values = []\n",
    "    train_actual_values = []\n",
    "    for i in train_user_business_combos:\n",
    "        prediction = baseline_score(master_baselines_dataframe,i[0],i[1])\n",
    "        #prediction = round(prediction)  ###this line is better off hidden\n",
    "        train_predicted_values.append(prediction)\n",
    "        train_actual_values.append(i[2])\n",
    "    \n",
    "    train_results = pd.DataFrame({\n",
    "            'predicted_values': train_predicted_values,\n",
    "            'actual_values': train_actual_values})\n",
    "    test_predicted_values = []\n",
    "    test_actual_values = []\n",
    "    \n",
    "    \n",
    "    for i in test_user_business_combos:\n",
    "        prediction = baseline_score(master_baselines_dataframe,i[0],i[1])\n",
    "        #prediction = round(prediction)  ###this line is better off hidden\n",
    "        test_predicted_values.append(prediction)\n",
    "        test_actual_values.append(i[2])\n",
    "    \n",
    "    test_results = pd.DataFrame({\n",
    "            'predicted_values': test_predicted_values,\n",
    "            'actual_values': test_actual_values})\n",
    "\n",
    "    return test_results,train_results,user_baselines_matrix,business_baselines_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_predictions_set = baseline_predictions(train,test)\n",
    "test_results = baseline_predictions_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_results = baseline_predictions_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RMSE  \n",
    "def RMSE(results):\n",
    "    \"\"\"\n",
    "    Calculate the root mean squared error between a matrix of real ratings and predicted ratings\n",
    "    :param real: A matrix containing the real ratings (with 'NaN' for any missing elements)\n",
    "    :param predicted: A matrix of predictions\n",
    "    :return: The RMSE as a float\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean(np.square(results['actual_values'] - results['predicted_values'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0686277753151672"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RMSE of the arithmetic baselines on the test set:\n",
    "RMSE(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87568246661790661"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RMSE of the arithmetic baselines on the train set:\n",
    "RMSE(train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Formula for endogenously calculating user and business average stars\n",
    "\n",
    "def endog_avg(dataframe):\n",
    "    users_list = list(set(dataframe['user_id']))\n",
    "    business_list = list(set(dataframe['business_id']))\n",
    "    \n",
    "    user_avg_stars_endog = []\n",
    "    for i in users_list:\n",
    "        filtered_df = dataframe[dataframe['user_id']==i]\n",
    "        mean_stars = np.mean(filtered_df['stars'])\n",
    "        user_avg_stars_endog.append(mean_stars)\n",
    "    \n",
    "    user_stars_dict = dict(zip(users_list,user_avg_stars_endog))\n",
    "\n",
    "    bus_avg_stars_endog = []\n",
    "    for i in business_list:\n",
    "        filtered_df = dataframe[dataframe['business_id']==i]\n",
    "        mean_stars = np.mean(filtered_df['stars'])\n",
    "        bus_avg_stars_endog.append(mean_stars)\n",
    "    \n",
    "    bus_stars_dict = dict(zip(business_list,bus_avg_stars_endog))\n",
    "    \n",
    "    #Add endogenously-calculated user and business average stars to the dataframe\n",
    "    user_avg_stars = []\n",
    "    for i in dataframe['user_id']:\n",
    "        user_avg_stars.append(user_stars_dict[i])\n",
    "    dataframe = dataframe.assign(user_avg_stars = user_avg_stars)\n",
    "\n",
    "    bus_avg_stars = []\n",
    "    for i in dataframe['business_id']:\n",
    "        bus_avg_stars.append(bus_stars_dict[i])\n",
    "    dataframe = dataframe.assign(bus_avg_stars = bus_avg_stars)\n",
    "    \n",
    "    #Add endogenously-calculated user and business average stars to the dataframe\n",
    "    user_avg_stars = []\n",
    "    for i in dataframe['user_id']:\n",
    "        user_avg_stars.append(user_stars_dict[i])\n",
    "    dataframe = dataframe.assign(user_avg_stars = user_avg_stars)\n",
    "\n",
    "    bus_avg_stars = []\n",
    "    for i in dataframe['business_id']:\n",
    "        bus_avg_stars.append(bus_stars_dict[i])\n",
    "    dataframe = dataframe.assign(bus_avg_stars = bus_avg_stars)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = endog_avg(train)\n",
    "test = endog_avg(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RIDGE REGRESSION!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = list(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_ridge(dataframe):\n",
    "    predictors = list(dataframe.columns)\n",
    "    predictors.remove('business_id')\n",
    "    predictors.remove('review_date')\n",
    "    predictors.remove('review_id')\n",
    "    predictors.remove('text')\n",
    "    predictors.remove('user_id')\n",
    "    predictors.remove('elite')\n",
    "    predictors.remove('user_friends')\n",
    "    predictors.remove('user_name')\n",
    "    predictors.remove('yelping_since')\n",
    "    predictors.remove('indexed_id')\n",
    "    predictors.remove('address')\n",
    "    predictors.remove('attributes')\n",
    "    predictors.remove('categories')\n",
    "    predictors.remove('city')\n",
    "    predictors.remove('hours')\n",
    "    predictors.remove('is_open')\n",
    "    predictors.remove('latitude')\n",
    "    predictors.remove('longitude')\n",
    "    predictors.remove('business_name')\n",
    "    predictors.remove('neighborhood')\n",
    "    predictors.remove('postal_code')\n",
    "    predictors.remove('state')\n",
    "    predictors.remove('Restaurant_Status')\n",
    "    \n",
    "    new_dataframe = dataframe[predictors]\n",
    "    new_dataframe['elite_status'] = new_dataframe.elite_status.map(dict(Yes=1, No=0))\n",
    "    \n",
    "    return new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomashill/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "ridge_train = format_ridge(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_cool</th>\n",
       "      <th>review_funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_useful</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>...</th>\n",
       "      <th>compliment_writer</th>\n",
       "      <th>user_cool_count</th>\n",
       "      <th>fans</th>\n",
       "      <th>user_funny_count</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>user_useful_count</th>\n",
       "      <th>elite_status</th>\n",
       "      <th>business_review_count</th>\n",
       "      <th>user_avg_stars</th>\n",
       "      <th>bus_avg_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26713</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>4.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37534</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3.538462</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35661</th>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>2550</td>\n",
       "      <td>44</td>\n",
       "      <td>2550</td>\n",
       "      <td>1547</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>376</td>\n",
       "      <td>17341</td>\n",
       "      <td>152</td>\n",
       "      <td>9170</td>\n",
       "      <td>601</td>\n",
       "      <td>17822</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3.695652</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16762</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>4.354167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28147</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_cool  review_funny  stars  review_useful  compliment_cool  \\\n",
       "26713            1             0      4              1                5   \n",
       "37534            0             0      3              1                0   \n",
       "35661           22            18      5             24             2550   \n",
       "16762            0             0      5              0                0   \n",
       "28147            2             0      5              2                4   \n",
       "\n",
       "       compliment_cute  compliment_funny  compliment_hot  compliment_list  \\\n",
       "26713                0                 5               8                0   \n",
       "37534                0                 0               3                0   \n",
       "35661               44              2550            1547                1   \n",
       "16762                0                 0               0                0   \n",
       "28147                0                 4               2                0   \n",
       "\n",
       "       compliment_more      ...        compliment_writer  user_cool_count  \\\n",
       "26713                1      ...                        3                2   \n",
       "37534                1      ...                        1                1   \n",
       "35661              190      ...                      376            17341   \n",
       "16762                0      ...                        0                0   \n",
       "28147                0      ...                        1               19   \n",
       "\n",
       "       fans  user_funny_count  user_review_count  user_useful_count  \\\n",
       "26713     8                 4                106                  5   \n",
       "37534     2                 0                 56                  3   \n",
       "35661   152              9170                601              17822   \n",
       "16762     1                 0                 12                  1   \n",
       "28147     2                 3                 16                 13   \n",
       "\n",
       "       elite_status  business_review_count  user_avg_stars  bus_avg_stars  \n",
       "26713             1                     67        3.600000       4.233333  \n",
       "37534             1                      9        3.538462       3.333333  \n",
       "35661             1                      6        3.695652       4.500000  \n",
       "16762             0                     95        3.600000       4.354167  \n",
       "28147             0                     10        4.800000       4.600000  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomashill/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Format train and test dataframes accordingly\n",
    "ridge_train = format_ridge(train)\n",
    "ridge_test = format_ridge(test)\n",
    "\n",
    "x_train = add_constant(ridge_train.drop('stars',1))\n",
    "y_train = ridge_train['stars'].values\n",
    "y_train = y_train.reshape(len(x_train),1)\n",
    "\n",
    "x_test = add_constant(ridge_test.drop('stars',1))\n",
    "y_test = ridge_test['stars'].values\n",
    "y_test = y_test.reshape(len(x_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating lambda list\n",
    "lambdas = []\n",
    "for i in range(-5,5):\n",
    "    lambdas.append(10**i)\n",
    "\n",
    "#Ridge Regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def cv_optimize_ridge(x_train,y_train,lambdas,n_folds=10):\n",
    "    est = Ridge()\n",
    "    parameters = {'alpha': lambdas}\n",
    "    gs = GridSearchCV(est,param_grid=parameters,cv=n_folds,scoring=\"neg_mean_squared_error\")\n",
    "    gs.fit(x_train,y_train)\n",
    "    return gs\n",
    "fitmodel = cv_optimize_ridge(x_train,y_train,lambdas,n_folds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 10}"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitmodel.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Running the Ridge regression on the test set\n",
    "clf = Ridge(alpha= 1 )\n",
    "clf.fit(x_train, y_train)\n",
    "clf.predict(x_test)\n",
    "\n",
    "ridge_preds_test = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Running the Ridge regression on the train set\n",
    "clf = Ridge(alpha= 100 )\n",
    "clf.fit(x_train, y_train)\n",
    "clf.predict(x_train)\n",
    "\n",
    "ridge_preds_train = clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RMSE  \n",
    "def RMSE(actual,predicted):\n",
    "    \"\"\"\n",
    "    Calculate the root mean squared error between a matrix of real ratings and predicted ratings\n",
    "    :param real: A matrix containing the real ratings (with 'NaN' for any missing elements)\n",
    "    :param predicted: A matrix of predictions\n",
    "    :return: The RMSE as a float\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean(np.square(actual - predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7309934541268529"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the RMSE on the test set using Ridge\n",
    "RMSE(y_test,ridge_preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84852178783719645"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the RMSE on the train set using Ridge\n",
    "RMSE(y_train,ridge_preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SINGULAR VALUE DECOMPOSITION\n",
    "\n",
    "#SVD - setting up\n",
    "train_pivot = train.pivot(index = 'user_id', columns ='business_id', values = 'stars').fillna(0)\n",
    "train_matrix = train_pivot.as_matrix()\n",
    "train_matrix_mean = np.mean(train_matrix, axis = 1)\n",
    "train_matrix_demeaned = train_matrix - train_matrix_mean.reshape(-1, 1)\n",
    "\n",
    "test_pivot = test.pivot(index = 'user_id', columns ='business_id', values = 'stars').fillna(0)\n",
    "test_matrix = test_pivot.as_matrix()\n",
    "test_matrix_mean = np.mean(test_matrix, axis = 1)\n",
    "test_matrix_demeaned = test_matrix - test_matrix_mean.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting baseline averages\n",
    "user_baselines_matrix = baseline_predictions_set[2]\n",
    "business_baselines_matrix = baseline_predictions_set[3]\n",
    "\n",
    "overall_avg_stars = np.mean(train['stars']) #Perhaps change how this average is calculated\n",
    "    \n",
    "master_baselines_matrix = np.add(business_baselines_matrix,user_baselines_matrix) #Sum the two matrices\n",
    "master_baselines_matrix = master_baselines_matrix + overall_avg_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Singular Value Decomposition\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "U_train, sigma_train, Vt_train = svds(train_matrix_demeaned, k = 50)\n",
    "sigma_train = np.diag(sigma_train)\n",
    "\n",
    "U_test, sigma_test, Vt_test = svds(test_matrix_demeaned, k = 50)\n",
    "sigma_test = np.diag(sigma_test)\n",
    "\n",
    "train_predicted_ratings = np.dot(np.dot(U_train, sigma_train), Vt_train) + master_baselines_matrix #+ train_matrix_mean.reshape(-1, 1) #replace these with the baseline mean\n",
    "test_predicted_ratings = np.dot(np.dot(U_test, sigma_test), Vt_test) + master_baselines_matrix #+ test_matrix_mean.reshape(-1, 1) #replace these with the baseline mean\n",
    "\n",
    "train_preds_df = pd.DataFrame(train_predicted_ratings, columns = train_pivot.columns, index=train_pivot.index)\n",
    "test_preds_df = pd.DataFrame(test_predicted_ratings, columns = test_pivot.columns,index=test_pivot.index)\n",
    "\n",
    "#print(test_preds_df.shape)\n",
    "#test_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 50)\n"
     ]
    }
   ],
   "source": [
    "train_preds_df.shape\n",
    "small_df = train_preds_df.sample(n=50, axis=1)\n",
    "small_df2 = small_df.sample(n=50,axis=0)\n",
    "print(small_df2.shape)\n",
    "small_df2.head()\n",
    "vals=[]\n",
    "for i in small_df2.columns:\n",
    "    vals.append(small_df2[i].values.sum())\n",
    "\n",
    "small_df2['sums'] = vals\n",
    "small_df2.sort_values(by='sums', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting predicted values\n",
    "user_ids = list(set(train['user_id']))\n",
    "business_ids = list(set(train['business_id']))\n",
    "    \n",
    "#Getting user and business averages for full matrix    \n",
    "business_list = list(set(train['business_id']))\n",
    "user_list = list(set(train['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In order to test the accuracy of this, create a dataframe of user-business interactions that actually happened\n",
    "test_user_business_combos = list(zip(test['business_id'],\n",
    "                                         test['user_id'],\n",
    "                                         test['stars']))\n",
    "    \n",
    "train_user_business_combos = list(zip(train['business_id'],\n",
    "                                         train['user_id'],\n",
    "                                         train['stars']))\n",
    "\n",
    "train_predicted_values = []\n",
    "train_actual_values = []\n",
    "for i in train_user_business_combos:\n",
    "    prediction = train_preds_df[i[0]][i[1]]\n",
    "    #prediction = round(prediction)  ###this line is better off hidden\n",
    "    train_predicted_values.append(prediction)\n",
    "    train_actual_values.append(i[2])\n",
    "\n",
    "\n",
    "newlist = []\n",
    "for item in train_predicted_values:\n",
    "    if item > 5:\n",
    "        item = 5\n",
    "    newlist.append(item)\n",
    "train_predicted_values = newlist    \n",
    "    \n",
    "train_results_svd = pd.DataFrame({\n",
    "        'predicted_values': train_predicted_values,\n",
    "        'actual_values': train_actual_values})\n",
    "\n",
    "test_predicted_values = []\n",
    "test_actual_values = []\n",
    "    \n",
    "    \n",
    "for i in test_user_business_combos:\n",
    "    prediction = test_preds_df[i[0]][i[1]]\n",
    "    #prediction = round(prediction)  ###this line is better off hidden\n",
    "    test_predicted_values.append(prediction)\n",
    "    test_actual_values.append(i[2])\n",
    "\n",
    "newlist = []\n",
    "for item in test_predicted_values:\n",
    "    if item > 5:\n",
    "        item = 5\n",
    "    newlist.append(item)\n",
    "test_predicted_values = newlist \n",
    "\n",
    "test_results_svd = pd.DataFrame({\n",
    "        'predicted_values': test_predicted_values,\n",
    "        'actual_values': test_actual_values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RMSE  \n",
    "def RMSE(actual,predicted):\n",
    "    \"\"\"\n",
    "    Calculate the root mean squared error between a matrix of real ratings and predicted ratings\n",
    "    :param real: A matrix containing the real ratings (with 'NaN' for any missing elements)\n",
    "    :param predicted: A matrix of predictions\n",
    "    :return: The RMSE as a float\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean(np.square(actual - predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3574296321368511"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RMSE on the test set using SVD\n",
    "RMSE(test_results_svd['actual_values'],test_results_svd['predicted_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.33190580432705"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RMSE on the train set using SVD\n",
    "RMSE(train_results_svd['actual_values'],train_results_svd['predicted_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Some simple ensembling\n",
    "\n",
    "#train\n",
    "x_train_ensemble = pd.DataFrame({\n",
    "    'ridge_preds': list(ridge_preds_train),\n",
    "    'arith_preds': list(train_results['predicted_values']),\n",
    "    'svd_preds': list(train_results_svd['predicted_values'])})\n",
    "\n",
    "#test\n",
    "x_test_ensemble = pd.DataFrame({\n",
    "    'ridge_preds': list(ridge_preds_test),\n",
    "    'arith_preds': list(test_results['predicted_values']),\n",
    "    'svd_preds': list(test_results_svd['predicted_values'])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72747361527104459"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ridge method\n",
    "rm = Ridge(alpha=100.0)\n",
    "rm.fit(x_train_ensemble, y_train)\n",
    "\n",
    "train_predicted_scores_Ridge = rm.predict(x_train_ensemble)\n",
    "test_predicted_scores_Ridge = rm.predict(x_test_ensemble)\n",
    "\n",
    "#test RMSE of the three approaches ensembled using Ridge\n",
    "RMSE(y_test,test_predicted_scores_Ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above, the ensemble method with the three approaches stacked into a ridge regression model produces a RMSE on the test set of 0.727, which is the best of all models we were able to find. Some alternative ensemble models are demonstrated below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomashill/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5367768203443726"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN\n",
    "KNN = KNeighborsClassifier(n_neighbors=10)\n",
    "KNN.fit(x_train_ensemble,y_train)\n",
    "train_predicted_scores_KNN = KNN.predict(x_train_ensemble)\n",
    "test_predicted_scores_KNN = KNN.predict(x_test_ensemble)\n",
    "\n",
    "RMSE(y_test,test_predicted_scores_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomashill/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1082: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3403076216822609"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lasso\n",
    "lasso = LassoCV(fit_intercept=False)\n",
    "lasso.fit(x_train_ensemble,y_train)\n",
    "train_predicted_scores_Lasso = lasso.predict(x_train_ensemble)\n",
    "test_predicted_scores_Lasso = lasso.predict(x_test_ensemble)\n",
    "\n",
    "RMSE(y_test,test_predicted_scores_Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72589325736783528"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear Regression\n",
    "linear = LinearRegression(fit_intercept=False)\n",
    "linear.fit(x_train_ensemble,y_train)\n",
    "train_predicted_scores_Linear = linear.predict(x_train_ensemble)\n",
    "test_predicted_scores_Linear = linear.predict(x_test_ensemble)\n",
    "\n",
    "RMSE(y_test,test_predicted_scores_Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Meta ensemble:\n",
    "\n",
    "#train\n",
    "x_train_ensemble_meta = pd.DataFrame({\n",
    "    'Ridge': list(train_predicted_scores_Ridge),\n",
    "    'KNN': list(train_predicted_scores_KNN),\n",
    "    'Lasso': list(train_predicted_scores_Lasso),\n",
    "    'Linear': list(train_predicted_scores_Linear)})\n",
    "        \n",
    "#test\n",
    "x_test_ensemble_meta = pd.DataFrame({\n",
    "    'Ridge': list(test_predicted_scores_Ridge),\n",
    "    'KNN': list(test_predicted_scores_KNN),\n",
    "    'Lasso': list(test_predicted_scores_Lasso),\n",
    "    'Linear': list(test_predicted_scores_Linear)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74949184344584108"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Meta Ridge method\n",
    "rm = Ridge(alpha=100.0)\n",
    "rm.fit(x_train_ensemble_meta, y_train)\n",
    "\n",
    "train_predicted_scores_Ridge = rm.predict(x_train_ensemble_meta)\n",
    "test_predicted_scores_Ridge = rm.predict(x_test_ensemble_meta)\n",
    "\n",
    "RMSE(y_test,test_predicted_scores_Ridge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
